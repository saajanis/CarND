{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MacOSFile(object):\n",
    "    def __init__(self, f):\n",
    "        self.f = f\n",
    "\n",
    "    def __getattr__(self, item):\n",
    "        return getattr(self.f, item)\n",
    "\n",
    "    def read(self, n):\n",
    "        # print(\"reading total_bytes=%s\" % n, flush=True)\n",
    "        if n >= (1 << 31):\n",
    "            buffer = bytearray(n)\n",
    "            idx = 0\n",
    "            while idx < n:\n",
    "                batch_size = min(n - idx, 1 << 31 - 1)\n",
    "                # print(\"reading bytes [%s,%s)...\" % (idx, idx + batch_size), end=\"\", flush=True)\n",
    "                buffer[idx:idx + batch_size] = self.f.read(batch_size)\n",
    "                # print(\"done.\", flush=True)\n",
    "                idx += batch_size\n",
    "            return buffer\n",
    "        return self.f.read(n)\n",
    "\n",
    "    def write(self, buffer):\n",
    "        n = len(buffer)\n",
    "        print(\"writing total_bytes=%s...\" % n, flush=True)\n",
    "        idx = 0\n",
    "        while idx < n:\n",
    "            batch_size = min(n - idx, 1 << 31 - 1)\n",
    "            print(\"writing bytes [%s, %s)... \" % (idx, idx + batch_size), end=\"\", flush=True)\n",
    "            self.f.write(buffer[idx:idx + batch_size])\n",
    "            print(\"done.\", flush=True)\n",
    "            idx += batch_size\n",
    "\n",
    "def pickle_dump(obj, file_path):\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        return pickle.dump(obj, MacOSFile(f), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def pickle_load(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        return pickle.load(MacOSFile(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "\n",
    "def show_images(images, make_random=False, fig_title='Default title', CMAP=None):\n",
    "    count = len(images)\n",
    "    col_count = 5\n",
    "    rows = math.ceil(float(len(images)) / float(col_count))\n",
    "    fig = plt.figure(figsize=(4*int(col_count),2*rows))\n",
    "    fig.suptitle(fig_title, fontsize=16)\n",
    "    \n",
    "    for i in range(count):\n",
    "        image = images[i]\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        ax1 = fig.add_subplot(rows,col_count,i+1)\n",
    "        #ax1.set_title(labelssamples[i] + ' occurences', fontsize=8)\n",
    "        ax1.imshow(image, cmap=CMAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lesson_functions\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.feature import hog\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=True):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, \n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), \n",
    "                                  transform_sqrt=False, \n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, \n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), \n",
    "                       transform_sqrt=False, \n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features\n",
    "\n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    color1 = cv2.resize(img[:,:,0], size).ravel()\n",
    "    color2 = cv2.resize(img[:,:,1], size).ravel()\n",
    "    color3 = cv2.resize(img[:,:,2], size).ravel()\n",
    "    return np.hstack((color1, color2, color3))\n",
    "                        \n",
    "# Define a function to compute color histogram features \n",
    "# TODO: NEED TO CHANGE bins_range if reading .png files with mpimg!\n",
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features\n",
    "\n",
    "\n",
    "#Feature extraction\n",
    "def extract_features(img, cspace='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, hist_range=(0, 256)):\n",
    "    image = cv2.resize(img, (64, 64))\n",
    "\n",
    "    # apply color conversion if other than 'RGB'\n",
    "    if cspace != 'RGB':\n",
    "        if cspace == 'HSV':\n",
    "            feature_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV).astype(np.float32)/255  \n",
    "        elif cspace == 'LUV':\n",
    "            feature_image = cv2.cvtColor(image, cv2.COLOR_BGR2LUV).astype(np.float32)/255 \n",
    "        elif cspace == 'HLS':\n",
    "            feature_image = cv2.cvtColor(image, cv2.COLOR_BGR2HLS).astype(np.float32)/255 \n",
    "        elif cspace == 'YUV':\n",
    "            feature_image = cv2.cvtColor(image, cv2.COLOR_BGR2YUV).astype(np.float32)/255  \n",
    "    else: \n",
    "        feature_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)/255    \n",
    "\n",
    "    # Apply bin_spatial() to get spatial color features\n",
    "    spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "    # Apply color_hist() also with a color space option now\n",
    "    hist_features = color_hist(feature_image, nbins=hist_bins, bins_range=hist_range)\n",
    "\n",
    "    ch1 = feature_image[:,:,0]\n",
    "    ch2 = feature_image[:,:,1]\n",
    "    ch3 = feature_image[:,:,2]\n",
    "    # Compute individual channel HOG features for the entire image\n",
    "    hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False).ravel()\n",
    "    hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False).ravel()\n",
    "    hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False).ravel()\n",
    "    hog_features = np.hstack((hog1, hog2, hog3))\n",
    "\n",
    "    all_features = np.hstack((spatial_features, hist_features, hog_features))\n",
    "\n",
    "    \n",
    "    features = np.array(all_features).astype(np.float64)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find_cars assisting functions\n",
    "\n",
    "def draw_labeled_bboxes(img, labels, prev_accepted_bboxes_list_list):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        average_bbox = bbox #get_average_bbox(bbox, prev_accepted_bboxes_list_list)\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, average_bbox[0], average_bbox[1], (0,0,255), 6)\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "def get_average_bbox(bbox, prev_accepted_bboxes_list_list):\n",
    "    if len(prev_accepted_bboxes_list_list) == 0:\n",
    "        return bbox\n",
    "    \n",
    "    similar_prev_bboxes = [bbox]\n",
    "    for prev_accepted_bboxes_list in prev_accepted_bboxes_list_list:\n",
    "        if len(prev_accepted_bboxes_list) == 0:\n",
    "            continue\n",
    "        prev_similar_bbox = bb_intersection_over_union(bbox, prev_accepted_bboxes_list, 0.2)\n",
    "        if prev_similar_bbox != None:\n",
    "            similar_prev_bboxes.append(prev_similar_bbox)\n",
    "        \n",
    "    # Get average bbox\n",
    "    average_bbox = ((( int(np.mean([x1 for ((x1, y1), (x2, y2)) in similar_prev_bboxes])) ), int(np.mean([y1 for ((x1, y1), (x2, y2)) in similar_prev_bboxes])) ),\n",
    "                 (( int(np.mean([x2 for ((x1, y1), (x2, y2)) in similar_prev_bboxes]) )), int(np.mean([y2 for ((x1, y1), (x2, y2)) in similar_prev_bboxes])) ))\n",
    "    \n",
    "    return average_bbox\n",
    "\n",
    "\n",
    "def is_similar_prev_bboxes(bbox, prev_bboxes_list, scale):\n",
    "    global min_iou_for_scales\n",
    "    \n",
    "    if len(prev_bboxes_list) == 0:\n",
    "        return True\n",
    "    for prev_bboxes in prev_bboxes_list:\n",
    "        prev_bboxes_scale = prev_bboxes[scale]\n",
    "        if bb_intersection_over_union(bbox, prev_bboxes_scale, min_iou_for_scales[scale]) == None:\n",
    "            return False\n",
    "        \n",
    "    return True   \n",
    "        \n",
    "def bb_intersect(boxA, boxB):\n",
    "    return not (boxA[1][0] < boxB[0][0] or boxA[0][0] > boxB[1][0] or boxA[1][1] < boxB[0][1] or boxA[0][1] > boxB[1][1])       \n",
    "\n",
    "def bb_intersection_over_union(boxA, boxB_list, threshold): \n",
    "#     # Don't need this because we're storing prev bboxes regardless of them being shown in frame\n",
    "#     if len(boxB_list) == 0:\n",
    "#         return True\n",
    "    \n",
    "    for boxB in boxB_list:\n",
    "#         ##\n",
    "#         draw_img = np.copy(img)\n",
    "#         cv2.rectangle(draw_img, boxA[0], boxA[1], (255,0,0), 6) #blue\n",
    "#         cv2.rectangle(draw_img, boxB[0], boxB[1], (0,255,0), 6) #green\n",
    "#         x = 0\n",
    "        \n",
    "        if not bb_intersect(boxA, boxB):\n",
    "            continue\n",
    "        \n",
    "        # determine the (x, y)-coordinates of the intersection rectangle\n",
    "        xA = max(boxA[0][0], boxB[0][0])\n",
    "        yA = max(boxA[0][1], boxB[0][1])\n",
    "        xB = min(boxA[1][0], boxB[1][0])\n",
    "        yB = min(boxA[1][1], boxB[1][1])\n",
    "        # compute the area of intersection rectangle\n",
    "        interArea = (xB - xA + 1) * (yB - yA + 1)\n",
    "        # compute the area of both the prediction and ground-truth\n",
    "        # rectangles\n",
    "        boxAArea = (boxA[1][0] - boxA[0][0] + 1) * (boxA[1][1] - boxA[0][1] + 1)\n",
    "        boxBArea = (boxB[1][0] - boxB[0][0] + 1) * (boxB[1][1] - boxB[0][1] + 1)\n",
    "        # compute the intersection over union by taking the intersection\n",
    "        # area and dividing it by the sum of prediction + ground-truth\n",
    "        # areas - the interesection area\n",
    "        iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "        if iou > threshold:\n",
    "            return boxB\n",
    "    \n",
    "    # No similar bboxes found in boxB_list\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21096\n",
      "4.53 Seconds to train SVC...\n",
      "Test Accuracy of SVC =  0.9991\n",
      "My SVC predicts:  [ 0.  1.  0.  0.  0.  0.  0.  1.  0.  1.]\n",
      "For these 10 labels:  [ 0.  1.  0.  0.  0.  0.  0.  1.  0.  1.]\n",
      "0.0016 Seconds to predict 10 labels with SVC\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "#TODO: Shuffle dataset\n",
    "# Read in car and non-car images\n",
    "car_images = glob.iglob('./data/all_data/vehicles/**/*.png', recursive=True)\n",
    "not_car_images = glob.iglob('./data/all_data/non-vehicles/**/*.png', recursive=True)\n",
    "cars = []\n",
    "notcars = []\n",
    "for image in car_images:\n",
    "    cars.append(image)\n",
    "for image in not_car_images:\n",
    "    notcars.append(image)\n",
    "\n",
    "# cars = cars[:200]\n",
    "# notcars = notcars[:200]\n",
    "        \n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(cars)), np.zeros(len(notcars))))\n",
    "\n",
    "### TODO: Tweak these parameters and see how the results change.\n",
    "color_space = 'HSV' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 10  # HOG orientations\n",
    "pix_per_cell = 8 # HOG pixels per cell\n",
    "cell_per_block = 2 # HOG cells per block\n",
    "hog_channel = 0 # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (16, 16)\n",
    "histbin = 32 # Number of histogram bins\n",
    "histrange = (0, 256)\n",
    "spatial_feat = True # Spatial features on or off\n",
    "hist_feat = True # Histogram features on or off\n",
    "hog_feat = True # HOG features on or off\n",
    "y_start_stop = [None, None] # Min and max in y to search in slide_window()\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# # Get all features\n",
    "# all_features = []\n",
    "# for img in (cars+notcars):\n",
    "#     all_features.append(extract_features(cv2.imread(img), cspace=color_space, spatial_size=spatial_size, \n",
    "#                      hist_bins=histbin, hist_range=histrange))\n",
    "\n",
    "# # Save features\n",
    "# pickle.dump(all_features, open('all_features_3', 'wb'))\n",
    "#Load features\n",
    "all_features = pickle.load(open('all_features_3', 'rb'))\n",
    "\n",
    "# Fit a per-column scaler\n",
    "X_scaler.fit(all_features)\n",
    "# Apply the scaler to X\n",
    "scaled_features = X_scaler.transform(all_features)\n",
    "\n",
    "print(len(scaled_features))\n",
    " \n",
    "rand_state = np.random.randint(0, 10.0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    scaled_features, y, test_size=0.2, random_state=rand_state)\n",
    " \n",
    "svc = LinearSVC(C=100)\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    " \n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    " \n",
    "    \n",
    "    \n",
    "# #Save state\n",
    "# model_pickle = {}\n",
    "# model_pickle[\"svc\"] = svc\n",
    " \n",
    "# # Save model\n",
    "# pickle.dump(model_pickle, open('pickled_model_3', 'wb'))\n",
    "# Load model\n",
    "loaded_svc_model = pickle.load(open('pickled_model_3', 'rb'))\n",
    "\n",
    "svc = loaded_svc_model[\"svc\"]\n",
    "\n",
    "# Check the score of the SVC\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "n_predict = 10\n",
    "print('My SVC predicts: ', svc.predict(X_test[0:n_predict]))\n",
    "print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "ystart = 400\n",
    "ystop = 656\n",
    "xstart = 760\n",
    "window_scales = [0.5, 1.0, 1.5, 2.0]\n",
    "overlap_thresholds_for_scales = {0.5: 1, 1.0: 1, 1.5: 1, 2.0: 1} #was {0.5: 6, 1.0: 1, 1.5: 2, 2.0: 1}\n",
    "min_prev_bboxes_for_match = {0.5: 14, 1.0: 1, 1.5: 4, 2.0: 0}\n",
    "min_iou_for_scales = {0.5: 0.6, 1.0: 0.5, 1.5: 0.5, 2.0: 0.0}\n",
    "frame_count = 0\n",
    "cached_bounding_boxes = {}\n",
    "#cached_bounding_boxes = pickle.load(open('cached_bounding_boxes', 'rb'))\n",
    "prev_accepted_bboxes_list_list = []\n",
    "num_prev_bboxes_for_average = 25\n",
    "    \n",
    "# Define a single function that can extract features using hog sub-sampling and make predictions\n",
    "def find_cars(img, ystart, ystop, xstart, window_scales, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins, cspace=color_space):\n",
    "    global frame_count\n",
    "    global cached_bounding_boxes\n",
    "    global overlap_thresholds_for_scales\n",
    "    global min_prev_bboxes_for_match\n",
    "    cached_bounding_boxes_for_frame = {}\n",
    "    for scale in window_scales:\n",
    "        cached_bounding_boxes_for_frame[scale] = []\n",
    "    global prev_accepted_bboxes_list_list\n",
    "    global num_prev_bboxes_for_average\n",
    "    accepted_bounding_boxes_for_frame = []\n",
    "    \n",
    "    \n",
    "    draw_img = np.copy(img)\n",
    "    heat_img = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Compute draw_img and heat_img from scratch\n",
    "    orig_img_tosearch = img[ystart:ystop,xstart:,:]\n",
    "    for scale in window_scales:\n",
    "        if cspace=='HSV':\n",
    "            ctrans_tosearch = cv2.cvtColor(orig_img_tosearch, cv2.COLOR_RGB2HSV).astype(np.float32)/255\n",
    "        if scale != 1.0:\n",
    "            imshape = ctrans_tosearch.shape\n",
    "            ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "\n",
    "\n",
    "\n",
    "        ch1 = ctrans_tosearch[:,:,0]\n",
    "        ch2 = ctrans_tosearch[:,:,1]\n",
    "        ch3 = ctrans_tosearch[:,:,2]\n",
    "\n",
    "        # Define blocks and steps as above\n",
    "        nxblocks = (ch1.shape[1] // pix_per_cell) - cell_per_block + 1\n",
    "        nyblocks = (ch1.shape[0] // pix_per_cell) - cell_per_block + 1 \n",
    "        nfeat_per_block = orient*cell_per_block**2\n",
    "\n",
    "        # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "        window = 64\n",
    "        nblocks_per_window = (window // pix_per_cell) - cell_per_block + 1\n",
    "        cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "        nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "        nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "\n",
    "        # Compute individual channel HOG features for the entire image\n",
    "        hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "        hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "        hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "\n",
    "        for xb in range(nxsteps):\n",
    "            for yb in range(nysteps):\n",
    "                ypos = yb*cells_per_step\n",
    "                xpos = xb*cells_per_step\n",
    "                # Extract HOG for this patch\n",
    "                hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "                xleft = xpos*pix_per_cell\n",
    "                ytop = ypos*pix_per_cell\n",
    "\n",
    "                # Extract the image patch\n",
    "                subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "\n",
    "                # Get color features\n",
    "                spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "                hist_features = color_hist(subimg, nbins=hist_bins)\n",
    "\n",
    "                # Scale features and make a prediction\n",
    "                all_features = np.hstack((spatial_features, hist_features, hog_features))\n",
    "                features = np.array(all_features).astype(np.float64)\n",
    "                scaled_features = X_scaler.transform([all_features])\n",
    "                #test_features = X_scaler.transform(np.hstack((shape_feat, hist_feat)).reshape(1, -1))    \n",
    "                test_prediction = svc.predict(scaled_features)\n",
    "\n",
    "                if test_prediction == 1:\n",
    "                    xbox_left = np.int(xleft*scale)\n",
    "                    ytop_draw = np.int(ytop*scale)\n",
    "                    win_draw = np.int(window*scale)\n",
    "                    bbox = ((xbox_left+xstart, ytop_draw+ystart), (xbox_left+win_draw+xstart,ytop_draw+win_draw+ystart))\n",
    "                    cv2.rectangle(draw_img,bbox[0],bbox[1],(0,0,255),6) \n",
    "                    heat_img[ytop_draw+ystart:ytop_draw+win_draw+ystart, xbox_left+xstart:xbox_left+win_draw+xstart] += 1\n",
    "                    cached_bounding_boxes_for_frame[scale].append(bbox)\n",
    "\n",
    "    cached_bounding_boxes[frame_count] = cached_bounding_boxes_for_frame\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     # Load draw_img and heat_img from cache\n",
    "#     cached_bounding_boxes_for_frame = cached_bounding_boxes[frame_count]\n",
    "#     for scale in window_scales:\n",
    "#         cached_bounding_boxes_for_scale = cached_bounding_boxes_for_frame[scale]\n",
    "#         threshold_scale = overlap_thresholds_for_scales[scale]\n",
    "#         heat_img_scale = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "#         prev_bboxes_list = [cached_bounding_boxes[x] for x in [i for i in range(frame_count-min_prev_bboxes_for_match[scale], frame_count)] if x in cached_bounding_boxes]\n",
    "\n",
    "        \n",
    "#         for bbox in cached_bounding_boxes_for_scale:\n",
    "#             # Find if similar enough to all in prev_bboxes at this scale (frame 0 has FPs, so removing it)\n",
    "#             if frame_count != 0 and bbox[0][0] > xstart and \\\n",
    "#                 is_similar_prev_bboxes(bbox, prev_bboxes_list, scale):\n",
    "#                 cv2.rectangle(draw_img,bbox[0],bbox[1],(0,0,255),6) \n",
    "#                 heat_img_scale[bbox[0][1]:bbox[1][1], bbox[0][0]:bbox[1][0]] += 1\n",
    "#                 accepted_bounding_boxes_for_frame.append(bbox)\n",
    "        \n",
    "#         heat_img_scale[heat_img_scale < threshold_scale] = 0 \n",
    "#         heat_img = heat_img + heat_img_scale\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    heatmap = np.clip(heat_img, 0, 255)\n",
    "    labels = label(heatmap)\n",
    "    final_heat_img = draw_labeled_bboxes(np.copy(img), labels, prev_accepted_bboxes_list_list) \n",
    "    \n",
    "    prev_accepted_bboxes_list_list = [accepted_bounding_boxes_for_frame] + prev_accepted_bboxes_list_list[:num_prev_bboxes_for_average]   \n",
    "    \n",
    "    \n",
    "    frame_count = frame_count+1\n",
    "    return (final_heat_img, draw_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video draw_img_scale_all2.mp4\n",
      "[MoviePy] Writing video draw_img_scale_all2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 25/26 [00:54<00:02,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: draw_img_scale_all2.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "def process_image(image):\n",
    "    (heat_img, draw_img) = find_cars(image, ystart, ystop, xstart, window_scales[:3], svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, histbin)\n",
    "    return draw_img\n",
    "\n",
    "output_path = 'output_video.mp4'\n",
    "\n",
    "frame_count = 0\n",
    "output_path = 'draw_img_scale_all2.mp4'\n",
    "project_video = VideoFileClip(\"project_video.mp4\")#.subclip(24,25)\n",
    "project_clip = project_video.fl_image(process_image)\n",
    "project_clip.write_videofile(output_path, audio=False)\n",
    "\n",
    "pickle.dump(cached_bounding_boxes, open('cached_bounding_boxes', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0a4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
