# Load pickled data
import pickle
import numpy as np

# TODO: Fill this in based on where you saved the training and testing data

training_file = "./traffic-signs-data/train.p"
validation_file = "./traffic-signs-data/valid.p"
testing_file = "./traffic-signs-data/test.p"

with open(training_file, mode='rb') as f:
    train = pickle.load(f)
with open(validation_file, mode='rb') as f:
    valid = pickle.load(f)
with open(testing_file, mode='rb') as f:
    test = pickle.load(f)
    
X_train, y_train = train['features'], train['labels']
X_valid, y_valid = valid['features'], valid['labels']
X_test, y_test = test['features'], test['labels']

#TODO(saajan): Use the bounding box co-ordinates in the dataset and resize to 32*32
#################

### Replace each question mark with the appropriate value. 
### Use python, pandas or numpy methods rather than hard coding the results

# TODO: Number of training examples
n_train = X_train.shape[0]

# TODO: Number of validation examples
n_validation = X_valid.shape[0]

# TODO: Number of testing examples.
n_test = X_test.shape[0]

# TODO: What's the shape of an traffic sign image?
image_shape = X_train.shape[1:]

# TODO: How many unique classes/labels there are in the dataset.
n_classes = len(np.unique(y_train))

print("Number of training examples =", n_train)
print("Number of testing examples =", n_test)
print("Image data shape =", image_shape)
print("Number of classes =", n_classes)

##################


### Data exploration visualization code goes here.
### Feel free to use as many code cells as needed.
import matplotlib.pyplot as plt
# Visualizations will be shown in the notebook.
#TODO(saajan): uncomment below and do more visualization
#%matplotlib inline

plt.hist(y_train, alpha=0.5, label='training_labels', bins=43)
plt.hist(y_valid, alpha=0.5, label='validation_labels', bins=43)
plt.hist(y_test, alpha=0.5, label='test_labels', bins=43)
plt.legend(loc='upper right')
plt.show()

###################


### Preprocess the data here. It is required to normalize the data. Other preprocessing steps could include 
### converting to grayscale, etc.
### Feel free to use as many code cells as needed.
def normalize(image):
    lala1 = 0
    
def convert_to_grayscale(image):
    lala2 = 0

# normalize Xs
X_train = [normalize(X_train_image) for X_train_image in X_train]
X_valid = [normalize(X_valid_image) for X_valid_image in X_valid]
X_test = [normalize(X_test_image) for X_testX_train_image in X_test]

lala = 0