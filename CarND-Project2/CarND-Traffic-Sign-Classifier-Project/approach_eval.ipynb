{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 34799\n",
      "Number of testing examples = 12630\n",
      "Image data shape = (32, 32, 3)\n",
      "Number of classes = 43\n",
      "# Original_data\n",
      "# Original_normalized_data\n",
      "82.6776\n",
      "# Cropped_normalized_data\n",
      "48.38\n",
      "1.14006e-08\n",
      "# Cropped_grayscale_data\n",
      "# Cropped_grayscaled_normalized_data\n",
      "47.6308\n",
      "Done with data prep!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Load pickled data\n",
    "import pickle\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "\n",
    "# TODO: Fill this in based on where you saved the training and testing data\n",
    "\n",
    "DATA_DIR = \"./data/\"\n",
    "\n",
    "training_file = DATA_DIR + \"traffic-signs-data/train.p\"\n",
    "validation_file = DATA_DIR + \"traffic-signs-data/valid.p\"\n",
    "testing_file = DATA_DIR + \"traffic-signs-data/test.p\"\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, X_train_coords, X_train_sizes, y_train = np.asarray(train['features'], dtype=np.float32), train['coords'], train['sizes'], train['labels']\n",
    "X_valid, X_valid_coords,X_valid_sizes, y_valid = np.asarray(valid['features'], dtype=np.float32), valid['coords'], valid['sizes'], valid['labels']\n",
    "X_test, X_test_coords, X_test_sizes, y_test = np.asarray(test['features'], dtype=np.float32), test['coords'], test['sizes'], test['labels']\n",
    "\n",
    "#################\n",
    "\n",
    "### Replace each question mark with the appropriate value. \n",
    "### Use python, pandas or numpy methods rather than hard coding the results\n",
    "\n",
    "# TODO: Number of training examples\n",
    "n_train = X_train.shape[0]\n",
    "\n",
    "# TODO: Number of validation examples\n",
    "n_validation = X_valid.shape[0]\n",
    "\n",
    "# TODO: Number of testing examples.\n",
    "n_test = X_test.shape[0]\n",
    "\n",
    "# TODO: What's the shape of an traffic sign image?\n",
    "image_shape = X_train.shape[1:]\n",
    "\n",
    "# TODO: How many unique classes/labels there are in the dataset.\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)\n",
    "\n",
    "##################\n",
    "\n",
    "\n",
    "### Data exploration visualization code goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "# Visualizations will be shown in the notebook.\n",
    "#TODO(saajan): uncomment line below and plot and do more visualization\n",
    "# %matplotlib inline\n",
    " \n",
    "# plt.hist(y_train, alpha=0.5, label='training_labels', bins=43)\n",
    "# plt.hist(y_valid, alpha=0.5, label='validation_labels', bins=43)\n",
    "# plt.hist(y_test, alpha=0.5, label='test_labels', bins=43)\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.show()\n",
    "\n",
    "###################\n",
    "import random\n",
    "\n",
    "def show_sample_images(Xs, count):\n",
    "    fig = plt.figure()\n",
    "    for i in range(count):\n",
    "        index = random.randint(0, len(Xs)-1)\n",
    "        image = Xs[index].squeeze()\n",
    "        ax1 = fig.add_subplot(1,count,i+1)\n",
    "        ax1.imshow(image)\n",
    "        #ax1.imshow(image, cmap=\"gray\")\n",
    "        \n",
    "        #plt.imshow(image, cmap=\"gray\")\n",
    "        #plt.imshow(image)\n",
    "           \n",
    "# show_sample_images(X_train, 10)\n",
    "\n",
    "### Preprocess the data here. It is required to normalize the data. Other preprocessing steps could include \n",
    "### converting to grayscale, etc.\n",
    "### Feel free to use as many code cells as needed.    \n",
    "\n",
    "def saveAndRetrievePickle(transformFunc, featuresDict, mode, pickleFileName):\n",
    "    if mode == 'saveAndRetrieve':\n",
    "        X_train_features = np.array([transformFunc(X_train_image) for X_train_image in featuresDict['X_train']])\n",
    "        X_valid_features = np.array([transformFunc(X_valid_image) for X_valid_image in featuresDict['X_valid']])\n",
    "        X_test_features = np.array([transformFunc(X_test_image) for X_test_image in featuresDict['X_test']])\n",
    "             \n",
    "        new_features_dict = {'X_train': X_train_features, 'y_train': y_train, 'X_valid': X_valid_features,\\\n",
    "                            'y_valid': y_valid, 'X_test': X_test_features, 'y_test': y_test}\n",
    "    \n",
    "        with open(DATA_DIR + pickleFileName + '.pickle', 'wb') as handle:\n",
    "            pickle.dump(new_features_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "      \n",
    "    if mode == 'saveAndRetrieve' or mode == 'retrieve':\n",
    "        with open(DATA_DIR + pickleFileName + '.pickle', 'rb') as handle:\n",
    "            new_features_dict = pickle.load(handle)\n",
    "    \n",
    "    return new_features_dict\n",
    "            \n",
    "   \n",
    "# Original_data\n",
    "def noop_image(image):\n",
    "    return np.asarray(image, dtype=np.float32) \n",
    "\n",
    "print(\"# Original_data\")\n",
    "original_data = {'X_train': X_train, 'y_train': y_train, 'X_valid': X_valid, 'y_valid': y_valid, 'X_test': X_test, 'y_test': y_test}\n",
    "# original_data = saveAndRetrievePickle(noop_image, original_data, 'saveAndRetrieve', 'original_data')\n",
    "original_data = saveAndRetrievePickle(noop_image, original_data, 'retrieve', 'original_data') \n",
    "\n",
    "\n",
    "# Create cropped data\n",
    "#TODO(saajan): Reconsider zeroing out irrelevant area over resizing cropped image\n",
    "def extract_bounds_and_rescale(image, coord, size):\n",
    "    transformed_x = 32\n",
    "    transformed_y = 32\n",
    "    original_x = size[0]\n",
    "    original_y = size[1]\n",
    "      \n",
    "    x_multiplier = float(transformed_x)/float(original_x)\n",
    "    y_multiplier = float(transformed_y)/float(original_y)\n",
    "      \n",
    "    transformed_coord = (coord[0]* x_multiplier, coord[1] * y_multiplier, coord[2] * x_multiplier, coord[3] * y_multiplier)\n",
    "    transformed_coord = [int(np.rint(val)) for val in transformed_coord]\n",
    "      \n",
    "    ret_image = image.copy()\n",
    "    shape = image.shape\n",
    "     \n",
    "    ret_image[0:transformed_coord[0],:] = (0,0,0)\n",
    "    ret_image[:,0:transformed_coord[1]] = (0,0,0)\n",
    "    ret_image[transformed_coord[2]:shape[1],:] = (0,0,0)\n",
    "    ret_image[:,transformed_coord[3]:shape[0]] = (0,0,0)\n",
    "    #show_sample_images([ret_image], 1)\n",
    "    return np.asarray(ret_image, dtype=np.float32)\n",
    "\n",
    "\n",
    "# # extract_bounds_and_rescale Xs\n",
    "# X_train = np.array([extract_bounds_and_rescale(image, coord, size) for (image, coord, size) in zip(X_train, X_train_coords, X_train_sizes)])\n",
    "# X_valid = np.array([extract_bounds_and_rescale(image, coord, size) for (image, coord, size) in zip(X_valid, X_valid_coords,X_valid_sizes)])\n",
    "# X_test = np.array([extract_bounds_and_rescale(image, coord, size) for (image, coord, size) in zip(X_test, X_test_coords, X_test_sizes)])\n",
    "  \n",
    "# print(\"# Cropped_data\")\n",
    "# cropped_data = {'X_train': X_train, 'y_train': y_train, 'X_valid': X_valid, 'y_valid': y_valid, 'X_test': X_test, 'y_test': y_test}\n",
    "# with open(DATA_DIR + 'cropped_data.pickle', 'wb') as cropped_data_handle:\n",
    "#     pickle.dump(cropped_data, cropped_data_handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "  \n",
    "with open(DATA_DIR + 'cropped_data.pickle', 'rb') as cropped_data_handle:\n",
    "    cropped_data = pickle.load(cropped_data_handle)\n",
    "     \n",
    "# show_sample_images(cropped_data['X_train'], 10)\n",
    "\n",
    "\n",
    "# normalize Xs\n",
    "def normalize(image, mean_pixel):\n",
    "    result = (np.asarray(image, dtype=np.float32) - mean_pixel) / mean_pixel\n",
    "    #normalizer_func = np.vectorize(lambda val: (float(val)-float(mean_pixel))/float(mean_pixel))\n",
    "    return np.asarray(result, dtype=np.float32)\n",
    "\n",
    "print(\"# Original_normalized_data\")\n",
    "print(np.mean([np.mean(image) for image in original_data['X_train']]))\n",
    "# original_normalized_data = saveAndRetrievePickle(partial(normalize, mean_pixel=np.mean([np.mean(image) for image in original_data['X_train']])), original_data, 'saveAndRetrieve', 'original_normalized_data')\n",
    "original_normalized_data = saveAndRetrievePickle(partial(normalize, mean_pixel=np.mean([np.mean(image) for image in original_data['X_train']])), original_data, 'retrieve', 'original_normalized_data')\n",
    "\n",
    "print(\"# Cropped_normalized_data\")\n",
    "print(np.mean([np.mean(image) for image in cropped_data['X_train']]))\n",
    "# cropped_normalized_data = saveAndRetrievePickle(partial(normalize, mean_pixel=np.mean([np.mean(image) for image in cropped_data['X_train']])), cropped_data, 'saveAndRetrieve', 'cropped_normalized_data')\n",
    "cropped_normalized_data = saveAndRetrievePickle(partial(normalize, mean_pixel=np.mean([np.mean(image) for image in cropped_data['X_train']])), cropped_data, 'retrieve', 'cropped_normalized_data')\n",
    "   \n",
    "# Experiments\n",
    "vals = []\n",
    "for image in cropped_normalized_data['X_train']:\n",
    "    vals.append((np.mean(image)))\n",
    "print(np.mean(vals))    \n",
    "\n",
    "\n",
    "import cv2\n",
    "# convert_to_grayscale Xs\n",
    "def convert_to_grayscale(image):\n",
    "    return np.asarray(cv2.cvtColor(image, cv2.COLOR_RGB2GRAY), dtype=np.float32).reshape((32, 32, 1))\n",
    "    \n",
    "print(\"# Cropped_grayscale_data\")\n",
    "# cropped_grayscale_data = saveAndRetrievePickle(convert_to_grayscale, cropped_data, 'saveAndRetrieve', 'cropped_grayscale_data')\n",
    "cropped_grayscale_data = saveAndRetrievePickle(convert_to_grayscale, cropped_data, 'retrieve', 'cropped_grayscale_data') \n",
    "\n",
    "print(\"# Cropped_grayscaled_normalized_data\")\n",
    "print(np.mean([np.mean(image) for image in cropped_grayscale_data['X_train']]))\n",
    "# cropped_grayscaled_normalized_data = saveAndRetrievePickle(partial(normalize, mean_pixel=np.mean([np.mean(image) for image in cropped_grayscale_data['X_train']])), cropped_grayscale_data, 'saveAndRetrieve', 'cropped_grayscaled_normalized_data')\n",
    "cropped_grayscaled_normalized_data = saveAndRetrievePickle(partial(normalize, mean_pixel=np.mean([np.mean(image) for image in cropped_grayscale_data['X_train']])), cropped_grayscale_data, 'retrieve', 'cropped_grayscaled_normalized_data') \n",
    "\n",
    "#Naming\n",
    "original_data['name'] = 'original_data'\n",
    "original_normalized_data['name'] = 'original_normalized_data'\n",
    "cropped_data['name'] = 'cropped_data'\n",
    "cropped_normalized_data['name'] = 'cropped_normalized_data'\n",
    "cropped_grayscaled_normalized_data['name'] = 'cropped_grayscaled_normalized_data'\n",
    "#all_data = [original_data, original_normalized_data, cropped_data, cropped_normalized_data, cropped_grayscale_data, cropped_grayscaled_normalized_data] \n",
    "all_data = [original_normalized_data, cropped_grayscale_data] \n",
    "\n",
    "print('Done with data prep!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'current_data_dict' (dict)\n",
      "\n",
      "Image Shape: (32, 32, 3)\n",
      "\n",
      "Training Set:   34799 samples\n",
      "Validation Set: 4410 samples\n",
      "Test Set:       12630 samples\n",
      "(32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/500 [00:00<?, ?epochs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 500/500 [32:18<00:00,  3.86s/epochs]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaIAAACeCAYAAABwxA4NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6v8DDTr8gjs41RgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd5eb099390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracies: \n",
      "[0.79439064361311973, 0.92476795323912675, 0.9550849162846099, 0.97301646600753033, 0.97304520248260273, 0.97847639299979883, 0.98212592321009629, 0.99183884596097727, 0.98853415329739491, 0.99364924281146139, 0.994511336532659, 0.99597689588781291, 0.99643667921491996, 0.99683898962613871, 0.98971234805597863, 0.99468375528032416, 0.99821833960745998, 0.99103422513853978, 0.99669530733641776, 0.99474122821334077, 0.99600563236288531, 0.99623552400931059, 0.99606310526164543, 0.99715509066352481, 0.99741371878502261, 0.99617805109342228, 0.9973849823270784, 0.9988218052242881, 0.99715509066352481, 0.99606310526164543, 0.99839075835512514, 0.99574700424138762, 0.99910916980372999, 0.99919537917756263, 0.9977010833644645, 0.99735624586913418, 0.99793097502801809, 0.99991379062616736, 0.99991379062616736, 0.99985631771027905, 0.99591942297192448, 0.99709761774763639, 0.99603436880370122, 0.99540216672892901, 0.99873559585045546, 0.99807465731773903, 0.99870685939251125, 0.99879306876634388, 0.99890801459812062, 0.99896548751400904, 0.99752866461679934, 0.99419523549527289, 0.99813213023362746, 0.99931032500933936, 0.99692519899997123, 0.9988218052242881, 0.99928158855139515, 0.99729877295324576, 0.99841949481306935, 0.9982758125233484, 0.99879306876634388, 0.99709761776476469, 0.99158021782235117, 0.99841949481306935, 0.99887927814017641, 0.99873559585045546, 0.99931032500933936, 0.99988505416822326, 0.99468375529745245, 0.99887927814017641, 0.99956895313083705, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99356303342050056, 0.99778729273829703, 0.99954021667289294, 0.99959768958878126, 1.0, 0.99997126354205579, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.96361964425977886, 0.99410902612144025, 0.99879306876634388, 0.99939653438317189, 0.99991379062616736, 0.99928158855139515, 0.99818960314951577, 0.99658036150464091, 0.99933906146728357, 0.9973849823270784, 0.99862065001867872, 0.99864938647662294, 0.99836202189718093, 0.99956895313083705, 1.0, 0.99997126354205579, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99261473032547043, 0.99836202189718093, 0.99948274375700452, 0.99873559585045546, 0.99954021667289294, 0.99919537917756263, 0.9988505416822322, 0.99951148021494873, 0.99959768958878126, 0.99807465731773903, 0.99979884479439063, 0.99729877295324576, 0.99853444066197439, 0.99887927814017641, 0.99985631771027905, 0.99997126354205579, 0.99997126354205579, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99623552400931059, 0.99836202189718093, 0.99931032500933936, 0.99988505416822326, 0.99968389896261389, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Validation accuracies: \n",
      "[0.69886621298973794, 0.82131519201391134, 0.84489795899445241, 0.86712018118964296, 0.85986394465915739, 0.87505668936943526, 0.88367346941478664, 0.89206349157692355, 0.90340136059828091, 0.89160997740535775, 0.88956916002459541, 0.90158730112776464, 0.90453514744635344, 0.91791383171297791, 0.8979591834842483, 0.90204081589402529, 0.90770975037767232, 0.89160997710801038, 0.91746031751438062, 0.89659863948281393, 0.91201814085988497, 0.89909297057560511, 0.90680272116953009, 0.91383219941132732, 0.92358276627771974, 0.92766439884968621, 0.92993197230254709, 0.92494331068462798, 0.90476190478893637, 0.91269841272544427, 0.92698412676787434, 0.91632652963910788, 0.92358276622365665, 0.92154195043775766, 0.91496598569173659, 0.91133786802118866, 0.92018140594975473, 0.93424036283882295, 0.93492063467735065, 0.93469387730773612, 0.924489795161483, 0.92222222197893799, 0.91428571455603014, 0.91768707458664767, 0.93151927464673312, 0.93854875310478292, 0.93287981886442017, 0.93242630361159107, 0.93718820864381158, 0.93151927413313296, 0.91519274352088809, 0.91428571404242998, 0.93582766466940881, 0.94036281154809898, 0.92857142832814432, 0.93900226733041192, 0.93741496601342611, 0.92244897910526824, 0.93718820785989565, 0.91950113384091126, 0.92290249438512895, 0.92471655253109752, 0.92539682539682544, 0.93287981837785161, 0.9287981862113589, 0.92721088386717299, 0.93446711993812159, 0.94217687101861514, 0.91836734693877553, 0.92698412698412702, 0.93582766415580876, 0.94308390049707325, 0.94285714261385856, 0.94353741523630219, 0.94308390049707325, 0.94353741523630219, 0.94217687101861514, 0.94217687101861514, 0.94217687101861514, 0.94195011364900061, 0.94195011364900061, 0.94331065786668777, 0.94240362838822966, 0.94217687101861514, 0.94263038575784419, 0.94353741523630219, 0.94263038575784419, 0.94195011364900061, 0.94263038575784419, 0.94308390049707325, 0.94195011364900061, 0.94263038575784419, 0.94308390049707325, 0.94263038575784419, 0.94285714312745872, 0.94263038575784419, 0.94376417260591672, 0.94240362787462961, 0.94263038524424403, 0.94353741472270214, 0.94376417209231667, 0.94376417209231667, 0.94308389998347308, 0.94376417209231667, 0.94421768683154572, 0.94399092946193119, 0.94263038524424403, 0.94331065735308761, 0.94376417209231667, 0.94421768683154572, 0.94331065735308761, 0.94285714261385856, 0.94421768683154572, 0.94308389998347308, 0.94421768683154572, 0.94376417209231667, 0.94444444420116014, 0.94353741472270214, 0.94399092946193119, 0.94421768683154572, 0.94421768683154572, 0.94421768683154572, 0.94444444420116014, 0.94421768683154572, 0.94399092946193119, 0.94512471631000372, 0.94444444420116014, 0.94467120157077467, 0.94421768683154572, 0.94489795894038919, 0.94557823104923278, 0.92766439912000209, 0.93560090705651, 0.94308390049707325, 0.93696145049028112, 0.94308389998347308, 0.94217687050501508, 0.94625850315807625, 0.94625850315807625, 0.94512471631000372, 0.94467120157077467, 0.94376417209231667, 0.94421768734514577, 0.94376417260591672, 0.94399092997553125, 0.94353741523630219, 0.94353741523630219, 0.94376417260591672, 0.94285714312745872, 0.94285714312745872, 0.94126984154015714, 0.94172335627938619, 0.94172335627938619, 0.94195011364900061, 0.94195011364900061, 0.94217687101861514, 0.94240362838822966, 0.94217687101861514, 0.94195011364900061, 0.94217687101861514, 0.94240362838822966, 0.94217687101861514, 0.94172335627938619, 0.94240362838822966, 0.94172335627938619, 0.94149659890977166, 0.94149659890977166, 0.94195011364900061, 0.94172335627938619, 0.94172335627938619, 0.94172335627938619, 0.94172335627938619, 0.94195011364900061, 0.94149659890977166, 0.94149659890977166, 0.94217687101861514, 0.94172335627938619, 0.94126984154015714, 0.94172335627938619, 0.94126984154015714, 0.94172335627938619, 0.94126984154015714, 0.94104308417054261, 0.94172335627938619, 0.93990929732247008, 0.94081632680092808, 0.94104308417054261, 0.94126984154015714, 0.93990929732247008, 0.94104308417054261, 0.93990929732247008, 0.94104308417054261, 0.94104308417054261, 0.94058956943131355, 0.94081632680092808, 0.94058956943131355, 0.94058956943131355, 0.94013605469208461, 0.94149659890977166, 0.86780045302817066, 0.93469387730773612, 0.93537414968689558, 0.93922902470002634, 0.94263038551455991, 0.93560090705651, 0.93560090678619423, 0.93424036313617043, 0.94104308392725833, 0.93287981810753573, 0.93922902445674217, 0.94285714182994262, 0.93356008994606343, 0.94489795842678914, 0.94920634947666505, 0.95238095265126821, 0.9496598642158941, 0.95102040843358115, 0.95124716580319568, 0.95192743791203915, 0.95170068054242474, 0.95215419528165368, 0.95260771002088274, 0.95260771002088274, 0.95260771002088274, 0.95238095265126821, 0.95215419528165368, 0.95283446739049726, 0.95260771002088274, 0.95283446739049726, 0.95260771002088274, 0.95260771002088274, 0.95283446739049726, 0.95328798212972632, 0.95306122476011179, 0.95328798212972632, 0.95328798212972632, 0.95374149686895526, 0.95396825423856979, 0.95374149686895526, 0.95419501160818432, 0.95396825423856979, 0.95396825423856979, 0.95396825423856979, 0.95351473949934085, 0.95374149686895526, 0.95374149686895526, 0.95396825423856979, 0.95396825423856979, 0.95374149686895526, 0.95328798212972632, 0.95328798212972632, 0.95351473949934085, 0.95351473949934085, 0.95306122476011179, 0.95306122476011179, 0.95260771002088274, 0.95283446739049726, 0.95283446739049726, 0.95328798212972632, 0.95283446739049726, 0.95306122476011179, 0.95260771002088274, 0.95283446739049726, 0.95238095265126821, 0.95215419528165368, 0.95238095265126821, 0.95215419528165368, 0.95215419528165368, 0.95170068054242474, 0.95147392317281021, 0.95147392317281021, 0.95170068054242474, 0.95147392317281021, 0.95124716580319568, 0.95079365106396663, 0.95102040843358115, 0.95124716580319568, 0.95124716580319568, 0.95124716580319568, 0.9505668936943521, 0.95079365106396663, 0.95102040843358115, 0.95102040843358115, 0.95079365106396663, 0.95102040843358115, 0.95079365106396663, 0.95034013632473757, 0.95079365106396663, 0.9505668936943521, 0.95079365106396663, 0.95011337895512316, 0.9505668936943521, 0.95079365106396663, 0.9505668936943521, 0.95034013632473757, 0.9505668936943521, 0.9496598642158941, 0.95102040843358115, 0.9505668936943521, 0.95034013632473757, 0.9496598642158941, 0.94943310684627957, 0.95034013632473757, 0.94943310684627957, 0.90680272135875117, 0.93809523836555397, 0.93809523836555397, 0.94058956943131355, 0.94036281206169903, 0.93514739256056523, 0.92993197254583138, 0.93741496625671039, 0.94285714312745872, 0.93514739231728106, 0.94648526104129094, 0.92675736937122821, 0.93446712045172176, 0.93560090729979428, 0.94603174578846172, 0.94512471631000372, 0.94625850367167641, 0.94603174630206188, 0.94557823156283283, 0.94580498893244735, 0.94603174630206188, 0.94625850367167641, 0.94580498893244735, 0.94603174630206188, 0.94603174630206188, 0.94603174630206188, 0.94580498893244735, 0.94580498893244735, 0.94603174630206188, 0.94603174630206188, 0.94603174630206188, 0.94603174630206188, 0.94625850367167641, 0.94625850367167641, 0.94603174630206188, 0.94648526104129094, 0.94648526104129094, 0.94671201841090546, 0.94716553315013441, 0.94716553315013441, 0.94761904788936346, 0.94739229051974894, 0.94784580525897799, 0.94807256262859252, 0.94829931999820705, 0.94852607736782146, 0.94897959210705052, 0.94897959210705052, 0.94920634947666505, 0.94943310684627957, 0.94943310684627957, 0.94943310684627957, 0.94943310684627957, 0.9496598642158941, 0.94988662158550863, 0.95011337895512316, 0.94988662158550863, 0.94988662158550863, 0.94988662158550863, 0.9496598642158941, 0.94988662158550863, 0.94988662158550863, 0.9496598642158941, 0.94988662158550863, 0.9496598642158941, 0.94920634947666505, 0.94943310684627957, 0.94965986394557822, 0.94965986394557822, 0.94988662131519275, 0.94943310657596369, 0.94965986394557822, 0.94965986394557822, 0.94943310657596369, 0.94943310657596369, 0.94965986394557822, 0.95011337868480727, 0.9503401360544218, 0.95011337868480727, 0.9503401360544218, 0.9503401360544218, 0.9503401360544218, 0.95011337868480727, 0.95011337868480727, 0.9503401360544218, 0.95011337868480727, 0.9503401360544218, 0.95011337868480727, 0.9503401360544218, 0.95011337868480727, 0.95011337868480727, 0.95056689342403633, 0.9503401360544218, 0.95011337868480727, 0.9503401360544218, 0.95056689342403633, 0.95102040816326527, 0.9512471655328798, 0.95102040816326527, 0.95079365079365075, 0.9503401360544218, 0.95011337868480727, 0.9503401360544218, 0.95011337868480727, 0.95056689342403633, 0.9503401360544218, 0.95056689342403633, 0.95170068027210886, 0.9512471655328798, 0.95102040816326527, 0.9512471655328798, 0.93061224441139068, 0.93537414993017975, 0.93786848099593945, 0.93877550917688135, 0.93832199443765241, 0.94308390049707325, 0.94489795945398936, 0.94489795945398936, 0.94467120208437483, 0.94489795945398936, 0.94512471682360388, 0.9453514741932183, 0.94512471682360388, 0.9453514741932183, 0.9453514741932183, 0.94603174630206188, 0.94580498893244735, 0.94603174630206188, 0.94603174630206188, 0.94580498893244735, 0.94580498893244735, 0.94603174630206188, 0.94625850367167641, 0.94625850367167641, 0.94625850367167641, 0.94603174630206188, 0.94603174630206188, 0.94603174630206188, 0.94603174630206188, 0.94603174630206188, 0.94603174630206188, 0.94625850367167641, 0.94648526104129094, 0.94671201841090546, 0.94671201841090546, 0.94671201841090546, 0.94648526104129094, 0.94625850367167641, 0.94648526104129094, 0.94716553315013441, 0.94761904788936346, 0.94807256262859252, 0.94784580525897799, 0.94739229051974894, 0.94739229051974894, 0.94739229051974894, 0.94761904788936346, 0.94761904788936346, 0.94761904788936346, 0.94761904788936346, 0.94739229051974894, 0.94761904788936346, 0.94739229051974894, 0.94784580525897799, 0.94761904788936346, 0.94761904788936346, 0.94784580525897799, 0.94784580525897799, 0.94761904788936346, 0.94784580525897799, 0.94761904788936346, 0.94739229051974894, 0.94761904788936346, 0.94807256262859252, 0.94784580525897799, 0.94784580525897799, 0.94761904788936346, 0.94739229051974894, 0.94761904788936346, 0.94761904788936346, 0.94761904788936346, 0.94739229051974894, 0.94784580525897799, 0.94716553315013441, 0.94671201841090546, 0.94648526104129094, 0.94625850367167641, 0.94625850367167641, 0.94625850367167641, 0.94625850367167641, 0.94625850367167641, 0.94648526104129094, 0.94671201841090546, 0.94603174630206188, 0.94557823156283283]\n",
      "Model saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 0.939\n",
      "Stored 'current_data_dict' (dict)\n",
      "\n",
      "Image Shape: (32, 32, 1)\n",
      "\n",
      "Training Set:   34799 samples\n",
      "Validation Set: 4410 samples\n",
      "Test Set:       12630 samples\n",
      "(32, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/500 [00:00<?, ?epochs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  19%|█▉        | 96/500 [04:38<19:35,  2.91s/epochs]"
     ]
    }
   ],
   "source": [
    "%%capture output\n",
    "for index, data_dict in enumerate(all_data):\n",
    "    current_data_dict = data_dict\n",
    "    current_data_dict_name = data_dict['name']\n",
    "    %store current_data_dict\n",
    "    %store current_data_dict_name\n",
    "    %run LeNet_eval.ipynb 'current_data_dict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
